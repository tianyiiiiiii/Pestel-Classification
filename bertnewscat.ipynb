{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset\n",
    "# from datasets import Dataset\n",
    "from torch.utils.data import Dataset \n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>PESTEL_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/mortgage-...</td>\n",
       "      <td>Mortgage Deal Reached In 2008 Shows Pitfalls T...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>The Obama administration, which is pushing sta...</td>\n",
       "      <td>Loren Berlin</td>\n",
       "      <td>2012-02-05</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/women-in-...</td>\n",
       "      <td>Women in Business: Kate O'Brien Minson, Presid...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>Kate has lived and breathed the therapeutic ap...</td>\n",
       "      <td>Laura Dunn, ContributorSocial Media and Commun...</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/like-athl...</td>\n",
       "      <td>Like Athletes, Business Owners Need to Learn F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>Business owners and top executives can also \"w...</td>\n",
       "      <td>Mary Ellen Biery, ContributorResearch Speciali...</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/donald-tr...</td>\n",
       "      <td>Trump Could Trigger The Longest Recession Sinc...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>Yikes.</td>\n",
       "      <td>Ben Walsh</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/grocery-c...</td>\n",
       "      <td>Grocery Chains Made A Promise To The First Lad...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>An AP investigation found that major grocers o...</td>\n",
       "      <td>Mike Schneider, AP</td>\n",
       "      <td>2015-12-07</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffingtonpost.com/entry/mortgage-...   \n",
       "1  https://www.huffingtonpost.com/entry/women-in-...   \n",
       "2  https://www.huffingtonpost.com/entry/like-athl...   \n",
       "3  https://www.huffingtonpost.com/entry/donald-tr...   \n",
       "4  https://www.huffingtonpost.com/entry/grocery-c...   \n",
       "\n",
       "                                            headline  category  \\\n",
       "0  Mortgage Deal Reached In 2008 Shows Pitfalls T...  BUSINESS   \n",
       "1  Women in Business: Kate O'Brien Minson, Presid...  BUSINESS   \n",
       "2  Like Athletes, Business Owners Need to Learn F...  BUSINESS   \n",
       "3  Trump Could Trigger The Longest Recession Sinc...  BUSINESS   \n",
       "4  Grocery Chains Made A Promise To The First Lad...  BUSINESS   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  The Obama administration, which is pushing sta...   \n",
       "1  Kate has lived and breathed the therapeutic ap...   \n",
       "2  Business owners and top executives can also \"w...   \n",
       "3                                             Yikes.   \n",
       "4  An AP investigation found that major grocers o...   \n",
       "\n",
       "                                             authors        date PESTEL_label  \n",
       "0                                       Loren Berlin  2012-02-05     Economic  \n",
       "1  Laura Dunn, ContributorSocial Media and Commun...  2015-04-25     Economic  \n",
       "2  Mary Ellen Biery, ContributorResearch Speciali...  2015-01-19     Economic  \n",
       "3                                          Ben Walsh  2016-06-27     Economic  \n",
       "4                                 Mike Schneider, AP  2015-12-07     Economic  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/balancednewcategory.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PESTEL_label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Economic</td>\n",
       "      <td>Mortgage Deal Reached In 2008 Shows Pitfalls T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Economic</td>\n",
       "      <td>Women in Business: Kate O'Brien Minson, Presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic</td>\n",
       "      <td>Like Athletes, Business Owners Need to Learn F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economic</td>\n",
       "      <td>Trump Could Trigger The Longest Recession Sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Economic</td>\n",
       "      <td>Grocery Chains Made A Promise To The First Lad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PESTEL_label                                            content\n",
       "0     Economic  Mortgage Deal Reached In 2008 Shows Pitfalls T...\n",
       "1     Economic  Women in Business: Kate O'Brien Minson, Presid...\n",
       "2     Economic  Like Athletes, Business Owners Need to Learn F...\n",
       "3     Economic  Trump Could Trigger The Longest Recession Sinc...\n",
       "4     Economic  Grocery Chains Made A Promise To The First Lad..."
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"content\"] = df[\"headline\"] + \" \" + df[\"short_description\"]\n",
    "df = df[['PESTEL_label', 'content']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert content to string and handle 'NaN' values\n",
    "df['content'] = df['content'].apply(lambda x: '' if pd.isna(x) else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('\\n', ' ').strip()\n",
    "    return text\n",
    "\n",
    "df['content'] = df['content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['PESTEL_label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, pestel_to_idx):\n",
    "        self.df = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pestel_to_idx = pestel_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index] \n",
    "        content = row['content']\n",
    "        label = row['PESTEL_label']\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            content,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'targets': torch.tensor(self.pestel_to_idx[label], dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "pestel_to_idx = {\n",
    "    \"Political\": 0,\n",
    "    \"Economic\": 1,\n",
    "    \"Social\": 2,\n",
    "    \"Technological\": 3,\n",
    "    \"Environmental\": 4,\n",
    "    \"Legal\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "MAX_LEN = 256 # can try 128\n",
    "BATCH_SIZE = 16 # can try 32 / 64\n",
    "\n",
    "train_set = NewsDataset(train_df, tokenizer, MAX_LEN, pestel_to_idx)\n",
    "test_set = NewsDataset(test_df, tokenizer, MAX_LEN, pestel_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_model = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PestelClassifier(torch.nn.Module):\n",
    "    def __init__(self, distilbert, num_classes):\n",
    "        super(PestelClassifier, self).__init__()\n",
    "        self.distilbert = distilbert\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.output = torch.nn.Linear(768, num_classes)\n",
    "        \n",
    "        # self.classifier = torch.nn.Sequential(\n",
    "        #     torch.nn.Linear(768, 256),\n",
    "        #     torch.nn.ReLU(),\n",
    "        #     torch.nn.Dropout(0.3),\n",
    "        #     torch.nn.Linear(256, num_classes)\n",
    "        # )\n",
    "\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output = self.distilbert(ids, attention_mask=mask)\n",
    "        output = self.dropout(output[0][:, 0, :])  # CLS token\n",
    "        output = self.output(output)\n",
    "        return output\n",
    "    \n",
    "        # x = self.distilbert(ids, attention_mask=mask).last_hidden_state[:, 0, :]  # CLS\n",
    "        # x = self.classifier(x)\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PestelClassifier(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (output): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 6  # For PESTEL\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PestelClassifier(distilbert_model, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-7 # can try higher \n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 840/840 [30:34<00:00,  2.18s/it, loss=1.8] \n",
      "Epoch 1 - Testing: 100%|██████████| 210/210 [01:51<00:00,  1.89it/s, loss=1.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.7704, Accuracy: 0.2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 840/840 [32:21<00:00,  2.31s/it, loss=1.8]   \n",
      "Epoch 2 - Testing: 100%|██████████| 210/210 [01:46<00:00,  1.98it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.7249, Accuracy: 0.3402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 840/840 [27:38<00:00,  1.97s/it, loss=1.65]\n",
      "Epoch 3 - Testing: 100%|██████████| 210/210 [01:33<00:00,  2.23it/s, loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 1.6590, Accuracy: 0.4497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 840/840 [25:19<00:00,  1.81s/it, loss=1.76]\n",
      "Epoch 4 - Testing: 100%|██████████| 210/210 [01:33<00:00,  2.25it/s, loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 1.5577, Accuracy: 0.5179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training:  46%|████▌     | 387/840 [12:38<14:20,  1.90s/it, loss=1.61]"
     ]
    }
   ],
   "source": [
    "# change to methods and call -> train for train and test loader, eval for val loader\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\")\n",
    "    for batch in train_bar:\n",
    "        ids = batch['ids'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids, mask)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    test_bar = tqdm(test_loader, desc=f\"Epoch {epoch+1} - Testing\")\n",
    "    for batch in test_bar:\n",
    "        ids = batch['ids'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(ids, mask)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "            test_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
