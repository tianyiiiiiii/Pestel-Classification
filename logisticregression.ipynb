{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial from Earthly - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/yty/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/yty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define the function to clean the news title column\n",
    "def cleaned_desc_column(text):\n",
    "  # Remove commas\n",
    "  text = re.sub(r',', '', text)\n",
    "  # Remove extra spaces\n",
    "  text = re.sub(r'\\s+', ' ', text)\n",
    "  # Remove full stops\n",
    "  text = re.sub(r'\\.', '', text)\n",
    "  # Remove single quotes and double quotes\n",
    "  text = re.sub(r\"['\\\"]\", '', text)\n",
    "  # Remove other non-word characters\n",
    "  text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "  text_token = word_tokenize(text)\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "\n",
    "  filtered_text = []\n",
    "\n",
    "  for sw in text_token:\n",
    "    if sw not in stop_words:\n",
    "        filtered_text.append(sw)\n",
    "\n",
    "  text = \" \".join(filtered_text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/balancednewcategory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>PESTEL_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/mortgage-...</td>\n",
       "      <td>Mortgage Deal Reached In 2008 Shows Pitfalls T...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>The Obama administration, which is pushing sta...</td>\n",
       "      <td>Loren Berlin</td>\n",
       "      <td>2012-02-05</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/women-in-...</td>\n",
       "      <td>Women in Business: Kate O'Brien Minson, Presid...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>Kate has lived and breathed the therapeutic ap...</td>\n",
       "      <td>Laura Dunn, ContributorSocial Media and Commun...</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/like-athl...</td>\n",
       "      <td>Like Athletes, Business Owners Need to Learn F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>Business owners and top executives can also \"w...</td>\n",
       "      <td>Mary Ellen Biery, ContributorResearch Speciali...</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/donald-tr...</td>\n",
       "      <td>Trump Could Trigger The Longest Recession Sinc...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>Yikes.</td>\n",
       "      <td>Ben Walsh</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/grocery-c...</td>\n",
       "      <td>Grocery Chains Made A Promise To The First Lad...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>An AP investigation found that major grocers o...</td>\n",
       "      <td>Mike Schneider, AP</td>\n",
       "      <td>2015-12-07</td>\n",
       "      <td>Economic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffingtonpost.com/entry/mortgage-...   \n",
       "1  https://www.huffingtonpost.com/entry/women-in-...   \n",
       "2  https://www.huffingtonpost.com/entry/like-athl...   \n",
       "3  https://www.huffingtonpost.com/entry/donald-tr...   \n",
       "4  https://www.huffingtonpost.com/entry/grocery-c...   \n",
       "\n",
       "                                            headline  category  \\\n",
       "0  Mortgage Deal Reached In 2008 Shows Pitfalls T...  BUSINESS   \n",
       "1  Women in Business: Kate O'Brien Minson, Presid...  BUSINESS   \n",
       "2  Like Athletes, Business Owners Need to Learn F...  BUSINESS   \n",
       "3  Trump Could Trigger The Longest Recession Sinc...  BUSINESS   \n",
       "4  Grocery Chains Made A Promise To The First Lad...  BUSINESS   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  The Obama administration, which is pushing sta...   \n",
       "1  Kate has lived and breathed the therapeutic ap...   \n",
       "2  Business owners and top executives can also \"w...   \n",
       "3                                             Yikes.   \n",
       "4  An AP investigation found that major grocers o...   \n",
       "\n",
       "                                             authors        date PESTEL_label  \n",
       "0                                       Loren Berlin  2012-02-05     Economic  \n",
       "1  Laura Dunn, ContributorSocial Media and Commun...  2015-04-25     Economic  \n",
       "2  Mary Ellen Biery, ContributorResearch Speciali...  2015-01-19     Economic  \n",
       "3                                          Ben Walsh  2016-06-27     Economic  \n",
       "4                                 Mike Schneider, AP  2015-12-07     Economic  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df['short_description']\n",
    "df['combined'] = df['headline'] + \" \" + df['short_description']\n",
    "X = df['combined']\n",
    "y = df['PESTEL_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11760,)\n",
      "(5040,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size = 0.30, random_state = 90)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7456632653061225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "#                ('clf', LogisticRegression(max_iter=1000)),])\n",
    "lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2),\n",
    "     min_df=3, max_df=0.9, stop_words='english')),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "\n",
    "# Train the logistic regression model on the training set\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Pipeline is not fitted yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/pipeline.py:54\u001b[0m, in \u001b[0;36m_raise_or_warn_if_not_fitted\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/pipeline.py:787\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 787\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/feature_extraction/text.py:2126\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[1;32m   2112\u001b[0m \n\u001b[1;32m   2113\u001b[0m \u001b[38;5;124;03mUses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[1;32m   2125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2126\u001b[0m \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe TF-IDF vectorizer is not fitted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2128\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtransform(raw_documents)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/utils/validation.py:1757\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/pipeline.py:782\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform the data, and apply `predict` with the final estimator.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[1;32m    742\u001b[0m \u001b[38;5;124;03mCall `transform` of each transformer in the pipeline. The transformed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03m    Result of calling `predict` on the final estimator.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m# TODO(1.8): Remove the context manager and use check_is_fitted(self)\u001b[39;00m\n\u001b[0;32m--> 782\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _raise_or_warn_if_not_fitted(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    783\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/pipeline.py:56\u001b[0m, in \u001b[0;36m_raise_or_warn_if_not_fitted\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline is not fitted yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# we only get here if the above didn't raise\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Pipeline is not fitted yet."
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.7549603174603174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate the accuracy of the model\n",
    "print(f\"Accuracy is: {accuracy_score(y_pred,y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Political\n",
      "Technological\n",
      "Social\n",
      "Technological\n",
      "Social\n",
      "Political\n"
     ]
    }
   ],
   "source": [
    "news = [\"Biden to Sign Executive Order That Aims to Make Child Care Cheaper\",\n",
    "       \"Google Stock Loses $57 Billion Amid Microsoft's AI 'Lead'—And \\\n",
    "       Reports It Could Be Replaced By Bing On Some Smartphones\",\n",
    "       \"Poland suspends food imports from Ukraine to assist its farmers\",\n",
    "       \"Can AI Solve The Air Traffic Control Problem? Let's Find Out\",\n",
    "       \"Woman From Odisha Runs 42.5 KM In UK Marathon Wearing A Saree\",\n",
    "       \"Hillary Clinton: Trump cannot win the election - but Biden will\",\n",
    "       ]\n",
    "\n",
    "predicted = lr.predict(news)\n",
    "\n",
    "for doc, PESTEL_label in zip(news, predicted):\n",
    "     print(PESTEL_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
